{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir=\"~/Desktop/biology/breast_cancer/data/\"\n",
    "# ubunto:\n",
    "# old samples\n",
    "dir1=\"~/Dropbox/CyTOF_Breast/Kaplan_1st/\"\n",
    "# new samples\n",
    "dir2 = '~/Dropbox/CyTOF_Breast/Kaplan_2nd/data_afterGating/processed data/'\n",
    "dir3 = '/home/yishai/Dropbox/CyTOF_Breast/Kaplan_3rd/data/'\n",
    "\n",
    "# parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir+'/functions/')\n",
    "\n",
    "dir_data = parent_dir+'/Data/'\n",
    "\n",
    "\n",
    "# show figures (figures are created and saved to file)\n",
    "show = True\n",
    "# create plot visualizations\n",
    "visualize = False\n",
    "subsample = False\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig(\"test.svg\", format=\"svg\")\n",
    "saveSVG = False\n",
    "\n",
    "# plot dir\n",
    "dir_plots = parent_dir+'/Plots_preproccess/'\n",
    "settings =        (dir_plots,show,saveSVG)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "envirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:54.700552Z",
     "start_time": "2022-12-11T11:15:54.680091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time \n",
    "start = time.process_time()\n",
    "import os\n",
    "\n",
    "import sys\n",
    "from IPython.display import Image, display\n",
    "# from tqdm import tqdm_notebook,tqdm\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "# import matplotlib.patches as  mpatches\n",
    "plt.rcParams[\"figure.figsize\"] = (5.0, 4.0)  # Set default size of plots.\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 180) #according to screen width\n",
    "# from pandas.core.base import PandasObject\n",
    "# PandasObject.view = view #allows view meth pd.view\n",
    "\n",
    "from scipy import signal, stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, DBSCAN, MiniBatchKMeans\n",
    "# from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "# from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "# from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from lmfit import minimize, Parameters\n",
    "# from umap import UMAP\n",
    "\n",
    "# import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "# import schist as scs\n",
    "\n",
    "# import networkx as nx\n",
    "\n",
    "# from castle.common import GraphDAG\n",
    "# from castle.metrics import MetricsDAG\n",
    "# from castle.datasets import IIDSimulation, DAG\n",
    "# from castle.algorithms import PC,Notears,GOLEM,ANMNonlinear,DirectLiNGAM,ICALiNGAM,NotearsLowRank\n",
    "# import notears.notears as notears\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.geometry.polygon import Polygon\n",
    "\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# from statsmodels.graphics._regressionplots_doc import _plot_influence_doc\n",
    "# from statsmodels.regression.linear_model import OLS\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from pandas import MultiIndex, Int16Dtype\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from plot_functions import *\n",
    "from usefull_functions import *\n",
    "from preprocess_functions import *\n",
    "from functions import *\n",
    "from impute_functions import *\n",
    "# from normalization import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "folderExists(dir_plots)\n",
    "folderExists(dir_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature names (Participating panel)\n",
    "\n",
    "Received CyTOF data is assumed to be only of intact and alive cells without duplicates \n",
    "\n",
    "each sample matrix with high dimensionality feature space (NamesAll);\n",
    "1. 1st cytof batch without: 'NCad','ECad','panKeratin'\n",
    "2. 2nd cytof batch without: 'p53', 'ZEB1'\n",
    "3. 3rd cytof batch without: 'p53', 'ZEB1'\n",
    "\n",
    "un-needed features (removed from  future processing); \n",
    "1. 'Live_Dead' (just noise amplification)\n",
    "2. 'Ir_DNA2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:54.721783Z",
     "start_time": "2022-12-11T11:15:54.701446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features are correct!\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "features['NamesAll'] = [  \n",
    "            'CD45','H4','H3', 'H3.3','NCad','ECad','panKeratin', 'K5', 'EpCam', 'H3K27me2', 'p53', 'EZH2',  \n",
    "            'gH2AX','aSMA','H3K36me2','H3K4me1','H3K9me2','H4K16ac',\n",
    "            'H2Aub', 'Vimentin', 'H3K64ac', 'BMI-1', 'ZEB1',  'H3K27ac', 'H4K20me3', 'ER', 'CD49f', 'CD24',\n",
    "            'GATA3',  'H3K9ac', 'H3K9me3', 'CD44', 'Ki67', 'K8-18', 'H3S28p', 'Ir_DNA2', 'Live_Dead',\n",
    "            'H3K36me3','H3K4me3','H3K27me3'\n",
    "        ]\n",
    "features['Core'] = ['H4','H3', 'H3.3']\n",
    "# extra cellular are outside the cell - except them everything is noramalized (in group \"ToNorm\")\n",
    "features['ToNorm'] = [    \n",
    "            'H4','H3', 'H3.3','panKeratin', 'K5', 'H3K27me2', 'p53', 'EZH2', 'gH2AX', 'aSMA', 'H3K36me2', 'H3K4me1', 'H3K9me2',\n",
    "            'H4K16ac', 'H2Aub', 'Vimentin', 'H3K64ac', 'BMI-1', 'ZEB1', 'H3K27ac', 'H4K20me3',\n",
    "            'ER', 'GATA3', 'H3K9ac', 'H3K9me3', 'Ki67', 'K8-18', 'H3S28p', 'H3K36me3','H3K4me3','H3K27me3',\n",
    "        ]\n",
    "features['CellIden'] = [  \n",
    "            'CD45', 'K5', 'EpCam', 'aSMA', 'Vimentin', 'ZEB1', 'ER', 'CD49f', 'CD24', 'GATA3', 'CD44', 'K8-18',\n",
    "            'Ki67','p53', 'NCad','ECad','panKeratin',\n",
    "        ]\n",
    "# everything that is not cell identity; 'H4','H3', 'H3.3' are excluded\n",
    "features['EpiCols'] = [   \n",
    "            'H3K27me2', 'H3K36me2', 'H3K4me1', 'H3K9me2', 'H4K16ac', 'H2Aub', 'H3K64ac',  \n",
    "            'H3K27ac', 'H4K20me3', 'BMI-1','EZH2','gH2AX',\n",
    "            'H3K9ac', 'H3K9me3', 'H3S28p','H3K36me3', 'H3K4me3','H3K27me3',\n",
    "        ]\n",
    "# remove un-needed features\n",
    "features = removeFeatures(features.copy(),features =['Ir_DNA2', 'Live_Dead'])\n",
    "# verify: no feature is both in CellIden and EpiCols (CellIden +EpiCols = NamesAll) \n",
    "if test_fetures(features): print (f'features are correct!') \n",
    "else:    print ('error')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from csv, and store in dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:56.012810Z",
     "start_time": "2022-12-11T11:15:54.722716Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dictionarys for data and used feature in each sample:\n",
    "k={}; names = {}\n",
    "names['figures'] = [1,1,2,2,2,3,3,3,3]\n",
    "names['norm_type'] = [1,1,2,2,2,2,2,2,2]\n",
    "names['all'] = features\n",
    "\n",
    "\n",
    "# 1st cytof batch\n",
    "# features diffrence of 1st cytof batch - copy into names dict\n",
    "f = removeFeatures(features.copy(),features =['NCad','ECad','panKeratin'])\n",
    "names['1'],names['2']  = f,f\n",
    "# copy csv data into data dict according to used features dict (names)\n",
    "k['1'] = pd.read_csv(dir1+\"BCK-01_noaf_18Sep2022_01_0.fcs_file_internal_comp_residual.csv\")[names['1']['NamesAll']]\n",
    "k['2'] = pd.read_csv(dir1+\"BCK-02_noaf_18Sep2022_01_0.fcs_file_internal_comp_residual.csv\")[names['2']['NamesAll']]\n",
    "\n",
    "# 2nd cytof batch\n",
    "# features diffrence of 2nd cytof batch - copy into names dict\n",
    "f = removeFeatures(features.copy(),features =['p53','ZEB1'])\n",
    "names['3'],names['4'],names['5']  = f,f,f\n",
    "k['3'] = pd.read_csv(dir2+\"export_BCK03_noaf_23Nov2022_01_0_final_cells - processed.csv\")[names['3']['NamesAll']]\n",
    "k['4'] = pd.read_csv(dir2+\"export_BCK04_noaf_23Nov2022_02_0_final_cells - processed.csv\")[names['4']['NamesAll']]\n",
    "k['5'] = pd.read_csv(dir2+\"export_BCK05_noaf_23Nov2022_01_0_final_cells - processed.csv\")[names['5']['NamesAll']]\n",
    "# later analysis k6 with duplicates\n",
    "# K6=pd.read_csv(dir2+\"export_BCK05_noaf_23Nov2022_01_0_final_cells.csv\")\n",
    "\n",
    "# 3d cytof batch ADDED H3K4me33\n",
    "# features diffrence of 3d cytof batch - copy into names dict\n",
    "f = removeFeatures(features.copy(),features =['p53','ZEB1'])\n",
    "names['4.1'],names['7'],names['8'],names['11']  = f,f,f,f\n",
    "k['4.1'] = pd.read_csv(dir3+\"export_BCK04_noaf_16Mar2023_03_0_FinalCells.csv\")[names['4.1']['NamesAll']]\n",
    "k['7'] = pd.read_csv(dir3+\"export_BCK07_noaf_16Mar2023_03_0_FinalCells.csv\")[names['7']['NamesAll']]\n",
    "k['8'] = pd.read_csv(dir3+\"export_BCK08_noaf_16Mar2023_02_0_FinalCells.csv\")[names['8']['NamesAll']]\n",
    "k['11'] = pd.read_csv(dir3+\"export_BCK11_noaf_16Mar2023_01_0_FinalCells.csv\")[names['11']['NamesAll']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# gating and transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gating - fix fluidigm gating result; In-gate and outlier removal (Samples with low number of events)\n",
    "\n",
    "Samples with low number of events are discarded (outliers) - remove outlier 99.99% from all\n",
    "\n",
    "In gate to achieve good normalization - gate on H3.3/H4 was too low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:57.286122Z",
     "start_time": "2022-12-11T11:15:56.691586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1: gated with method 1, initial size: 6195, after gating and outliers: 4811 (77.66%)\n",
      "k2: gated with method 1, initial size: 299471, after gating and outliers: 181275 (60.53%)\n",
      "k3: gated with method 2, initial size: 3968, after gating and outliers: 815 (20.54%)\n",
      "k4: gated with method 2, initial size: 401141, after gating and outliers: 374890 (93.46%)\n",
      "k5: gated with method 2, initial size: 79376, after gating and outliers: 68765 (86.63%)\n",
      "k4.1: gated with method 2, initial size: 111614, after gating and outliers: 110463 (98.97%)\n",
      "k7: gated with method 2, initial size: 70379, after gating and outliers: 66741 (94.83%)\n",
      "k8: gated with method 2, initial size: 130074, after gating and outliers: 124725 (95.89%)\n",
      "k11: gated with method 2, initial size: 41305, after gating and outliers: 38864 (94.09%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GateColumns=['H3.3','H4']#,'H3']#,'H3']\n",
    "for [i, K] , j in zip(k.items(), names['norm_type']):\n",
    "    initialSize = len(K)\n",
    "    if j==1:\n",
    "      K = Gate(K,'k' + i,['H3.3','H4'])\n",
    "    if j==2:\n",
    "      K = Gate(K,'k' + i,['H3','H3.3','H4'])\n",
    "    finalSize = len(K)\n",
    "    print (f'k{i}: gated with method {j}, initial size: {initialSize}, after gating and outliers: {finalSize} ({np.round(finalSize/initialSize*100,2)}%)')\n",
    "    k[i] = K.reset_index()\n",
    "    \n",
    "\n",
    "# k_gate = k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "impute\n",
    "\n",
    "impute EpiCols with the right dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n = names['all']['EpiCols'].copy()\n",
    "# remove cropped distrunutions\n",
    "# for f in ['H3K4me1','H3K4me3','H3K27me2','H3K36me2','H3S28p']:\n",
    "#     n.remove(f)\n",
    "# zeros = getZerosMat(k,index=['1','2','3','4','5'],columns = n)\n",
    "\n",
    "zeros = getZerosMat(k,columns = names['all']['NamesAll'].copy(),percent = 0)\n",
    "zeros.to_csv(settings[0]+'raw_zeros.csv')\n",
    "# print(zeros)\n",
    "# # m=\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_hist(k,NamesAll,figures,settings,func = sns.kdeplot ,title = '',Figname = '' ):\n",
    "    \n",
    "#     arr = np.linspace(0, 1, len (k.keys()))    \n",
    "#     colors = cm.rainbow(arr)\n",
    "#     for M in NamesAll: \n",
    "#         fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
    "        \n",
    "#         for [i, K],color,fig_num in zip(k.items(),colors,figures):\n",
    "#             fig_num -= 1\n",
    "#             ax[fig_num].set_ylim(0,5000)\n",
    "#             ax[fig_num].set_xlim(0,500)\n",
    "\n",
    "#             # sns.kdeplot(K[M],c=c,label='Tumor ' + i)\n",
    "#             try: #if K doesnt contain the feature pass..\n",
    "#               q=func(K[M],color=color,label='Tumor ' + i,ax = ax[fig_num])\n",
    "#               # sns.kdeplot(K2[M],c='g',label='Tumor 2')\n",
    "#               ax[fig_num].title.set_text(title)\n",
    "#               ax[fig_num].legend()\n",
    "              \n",
    "              \n",
    "#             except:\n",
    "#               pass\n",
    "        \n",
    "#         figname = Figname + M\n",
    "        \n",
    "#         dir,show,saveSVG = settings\n",
    "#         plt.savefig(dir+figname+'.png', format=\"png\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "#         if saveSVG:\n",
    "#             plt.savefig(dir+figname+'.svg', format=\"svg\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "#         if show:\n",
    "#             plt.show()\n",
    "#         else:\n",
    "#             plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i='1'\n",
    "# n=zeros.T[zeros.T['1'].notnull()].index.tolist()\n",
    "\n",
    "# nonzeros = MimalzerosOverlap(k[i].copy(),names[i]['Core']+names[i]['CellIden'],n)\n",
    "# features = nonzeros.columns\n",
    "# K = k[i].copy()\n",
    "# # features=['p53']\n",
    "# df = pd.DataFrame(index=['mse','mae','accuracy'],columns = features)\n",
    "\n",
    "# for feature in features:\n",
    "\n",
    "#     K,mse, mae, accuracy = xg(nonzeros,K,feature)\n",
    "#     df.at['mse',feature] = mse\n",
    "#     df.at['mae',feature] = mae\n",
    "#     df.at['accuracy',feature] = accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(zeros.T[zeros.T['1'].notnull()].index.tolist())\n",
    "# print(df.T.index)\n",
    "# print(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.T) \n",
    "# print(K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, K in k.items():\n",
    "#   dict ={}\n",
    "#   dict['k'] = K\n",
    "#   dict['names'] = names[i]\n",
    "#   dict['all'] = names['all']\n",
    "#   pickle_dump('k_raw'+i+'_dict', dict,dir_data)\n",
    "#   print('k'+i,'; saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " arcsinh data transformation\n",
    "  \n",
    "  transformation (semi log scaling): scale argument = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:57.623862Z",
     "start_time": "2022-12-11T11:15:57.287245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 ; arcsinh transformed\n",
      "k2 ; arcsinh transformed\n",
      "k3 ; arcsinh transformed\n",
      "k4 ; arcsinh transformed\n",
      "k5 ; arcsinh transformed\n",
      "k4.1 ; arcsinh transformed\n",
      "k7 ; arcsinh transformed\n",
      "k8 ; arcsinh transformed\n",
      "k11 ; arcsinh transformed\n"
     ]
    }
   ],
   "source": [
    "for i, K in k.items():\n",
    "    k[i] = arcsinh_transform(K)\n",
    "    print ('k' + i,'; arcsinh transformed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualization\n",
    "\n",
    "Kernel Distribution Estimation Plot (kdeplot) is the probability density function plot;\n",
    "1. can plot for the univariate (single variable) or multiple variables altogether. \n",
    "2. y = probability, x = feature value after arcsinh transformation (can be also negative)\n",
    "3. arcsinh probability density plot - analysis of herogeneity (division to multiple populations)\n",
    "\n",
    "results:\n",
    "1. cd45 - we want only the negative population\n",
    "2. close populations - epcam, vimentin,cd49f\n",
    "3. far populations - cd44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:16:40.368500Z",
     "start_time": "2022-12-11T11:16:03.415174Z"
    }
   },
   "outputs": [],
   "source": [
    "if visualize:\n",
    "#   interst=[  'CD45','CD44', 'EpCam', 'Vimentin', 'CD49f','CD45','H4','H3', 'H3.3','NCad','ECad','panKeratin',]\n",
    "  interst=names['all']['NamesAll']\n",
    "  plot_hist(k,interst,names['figures'],settings,\n",
    "            func = sns.kdeplot,title = 'ArcSinh Unnormalized',Figname = '1_Hist_ArcSinh_Unnormalized_' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split CD45 neg \n",
    "\n",
    "the only interesting population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:16:45.618105Z",
     "start_time": "2022-12-11T11:16:40.370107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1; value with highest *inverse* probability: 1.87\n",
      "k2; value with highest *inverse* probability: 2.172\n",
      "k3; value with highest *inverse* probability: 0.98\n",
      "k4; value with highest *inverse* probability: 0.06\n",
      "k5; value with highest *inverse* probability: 1.2298199181170908\n",
      "k4.1; value with highest *inverse* probability: 0.073\n",
      "k7; value with highest *inverse* probability: 0.12\n",
      "k8; value with highest *inverse* probability: 0.11\n",
      "k11; value with highest *inverse* probability: 0.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "KCD45Neg_ind ,min_x, min_y = {},{},{}\n",
    "\n",
    "for [i, K] , xMin in zip(k.items(),[1.87,2.172,0.98,0.06,1.2298199181170908,0.073,0.12,0.11,0.15]):\n",
    "    if xMin == None: #there  are 2 defined dist and minima can be found not manually\n",
    "         min_x[i],min_y[i] = splitInversePDF(K,i,'CD45')\n",
    "    else:\n",
    "        min_x[i] = xMin\n",
    "        if visualize:\n",
    "            min_x[i],min_y[i] = splitInversePDF(K,i,'CD45',min_x = xMin)\n",
    "    KCD45Neg_ind[i]= K['CD45']<min_x[i]\n",
    "    print(f'k{i}; value with highest *inverse* probability:', min_x[i])\n",
    "\n",
    "if visualize:\n",
    "    for i, K in k.items():\n",
    "        plotSplit(K,i,min_x[i],min_y[i],settings,Figname = '_cd45_split',log = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:20:23.595179Z",
     "start_time": "2022-12-11T11:20:23.218312Z"
    }
   },
   "outputs": [],
   "source": [
    "# if visualize:\n",
    "#   colors = cm.rainbow(np.linspace(0, 1, len (k.keys())))\n",
    "#   fig, ax = plt.subplots(1,2,figsize=(10,3))\n",
    "#   for i, K in k.items(): \n",
    "#     #   \n",
    "#     j =  names['figures'][int(i)-1]-1 \n",
    "#     sns.histplot(K.CD45,color=colors[int(i)-1],label='T'+i,stat='density',element='step',fill=False,ax = ax[j])\n",
    "#     ax[j].legend(loc='upper center',bbox_to_anchor=(1,1))\n",
    "#     ax[j].set_yscale('log')\n",
    "#     ax[j].title.set_text('cd45 split histplot')\n",
    "#   plt.savefig(dir_plots+'cd45_split_histplot.svg', format=\"svg\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "#   fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
    "#   for [i, K],[h, KCD45Neg] in zip( k.items(),kCD45Neg.items()):\n",
    "#       j =  names['figures'][int(i)-1]-1 \n",
    "#       sns.kdeplot(K.CD45,color=colors[int(i)-1],label='T'+i,ax = ax[j])\n",
    "#       sns.kdeplot(K.CD45,color=colors[int(i)-1],ls='--',label='T'+i+' CD45-',ax = ax[j])\n",
    "#       ax[j].legend(loc='upper center',bbox_to_anchor=(1,1))\n",
    "#       ax[j].set_yscale('log')\n",
    "#       ax[j].title.set_text('cd45 split kdeplot')\n",
    "#   plt.savefig(dir_plots+'cd45_split_kdeplot.svg', format=\"svg\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue only with CD45 neg population\n",
    "\n",
    "1 - delete cd45+ population and continue with k  = kCD45Neg\n",
    "\n",
    "2 - delete cd45 feature from data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1: CD45+ removal - initial: 4811, final:1772 (36.83%)\n",
      "k2: CD45+ removal - initial: 181275, final:39276 (21.67%)\n",
      "k4: CD45+ removal - initial: 374890, final:313781 (83.7%)\n",
      "k5: CD45+ removal - initial: 68765, final:63390 (92.18%)\n",
      "k4.1: CD45+ removal - initial: 110463, final:99457 (90.04%)\n",
      "k7: CD45+ removal - initial: 66741, final:57348 (85.93%)\n",
      "k8: CD45+ removal - initial: 124725, final:108977 (87.37%)\n",
      "k11: CD45+ removal - initial: 38864, final:33196 (85.42%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict ={}\n",
    "for i, K in k.items():\n",
    "    if i != '3':\n",
    "        newK = K[KCD45Neg_ind[i]].copy().reset_index()\n",
    "        print(f'k{i}: CD45+ removal - initial: {len(K)}, final:{len(newK)} ({np.round(len(newK)/len(K)*100,2)}%)')\n",
    "        dict[i ] = newK\n",
    "k =None;newK=None; k=dict \n",
    "\n",
    "dict ={}\n",
    "for i, K in k.items():\n",
    "  \n",
    "\n",
    "  # remove from features lists(names)\n",
    "  N = names[i]\n",
    "  for j, sublist in N.items():\n",
    "    try:\n",
    "      sublist.remove('CD45')\n",
    "    except:\n",
    "      pass\n",
    "    N[j] = sublist\n",
    "  dict[i] = N\n",
    "#   remove index 3 and copy to new dict\n",
    "names['figures'].pop(3-1)\n",
    "dict['figures'] = names['figures']\n",
    "names['norm_type'].pop(3-1)\n",
    "dict['norm_type'] = names['norm_type']\n",
    "dict['all'] = names['all']\n",
    "del names; names=dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normalize using new method on all intercellular markers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save pre normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, K in k.items():\n",
    "    try:\n",
    "      del dict;dict ={}\n",
    "    except:\n",
    "        dict ={}\n",
    "    dict['k'] = K\n",
    "    pickle_dump('k'+i+'_prenorm_dict', dict,dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommonFeatures = ['NCad','ECad','panKeratin',  'p53', 'ZEB1' ]\n",
    "\n",
    "\n",
    "# # remove from the  mutual list uncommonFeatures\n",
    "# N = names['1'].copy()\n",
    "\n",
    "# for j, sublist in N.items():\n",
    "#     for f in uncommonFeatures:\n",
    "#         try:\n",
    "#             sublist.remove(f)\n",
    "#         except:\n",
    "#             pass\n",
    "#     N[j] = sublist\n",
    "# names['1245'] = N\n",
    "\n",
    "# names['figures'].append(2)\n",
    "\n",
    "\n",
    "#  # remove from data\n",
    "# appendDict ={}\n",
    "# for i, KK in k.items():\n",
    "#     K=KK.copy()\n",
    "#     for f in uncommonFeatures:\n",
    "#         try:\n",
    "#             K = K.drop(columns=[f])\n",
    "#         except:\n",
    "#             pass\n",
    "#     # print (K.columns)\n",
    "#     appendDict[i ] = K\n",
    "    \n",
    "# # del k; k=dict \n",
    "\n",
    "# # append data\n",
    "# NamesAll = names['1245']['NamesAll']\n",
    "# k_append= pd.DataFrame(columns =NamesAll)\n",
    "# for i, K in appendDict.items():\n",
    "\n",
    "#     K= subsample_k(K[NamesAll].copy(),n=1771)\n",
    "#     K['by_sample'] = int(i)\n",
    "#     k_append = k_append.append(K, ignore_index=True)\n",
    "# by_sampleInd = k_append['by_sample'].copy()\n",
    "# k['1245'] = k_append\n",
    "\n",
    "# k['1245']['by_sample'] = by_sampleInd\n",
    "# # k_append['by_sample'] = by_sampleInd\n",
    "# # print(len(by_sampleInd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 step normalization:\n",
    "\n",
    "1- normalize gardient (TBD)\n",
    "\n",
    "1- normalize using core\n",
    "\n",
    "insight: since its the minima multiple rus with same effect as one run\n",
    "\n",
    "note: features to norm (i.e names[i]['ToNorm']) are different on each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:20:36.437744Z",
     "start_time": "2022-12-11T11:20:36.184723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 ; normalized with method 1\n",
      "k2 ; normalized with method 1\n",
      "k4 ; normalized with method 2\n",
      "k5 ; normalized with method 2\n",
      "k4.1 ; normalized with method 2\n",
      "k7 ; normalized with method 2\n",
      "k8 ; normalized with method 2\n",
      "k11 ; normalized with method 2\n"
     ]
    }
   ],
   "source": [
    "# if visualize:\n",
    "#   for i, K in k.items():\n",
    "#     print ('k' + i,', initial std:')\n",
    "#     print(K.std().to_frame().T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(k,sample,names):\n",
    "    for [i, K] , j in zip(k.items(), names['norm_type']):\n",
    "        \n",
    "        \n",
    "        # FIRST STEP - normalize_gardient by core \n",
    "        # SECOND STEP - normalize ToNorm fetures by the core features ['H3.3','H4']\n",
    "        \n",
    "        if j==1:\n",
    "          K=NormalizeNew2(K,names[i]['ToNorm'])\n",
    "          K = Mean_Core_normalization(K, names[i]['ToNorm'],coreFetures=['H3.3','H4'])\n",
    "          \n",
    "        elif j==2:\n",
    "          K=NormalizeNew(K,names[i]['ToNorm'])\n",
    "          K = Mean_Core_normalization(K, names[i]['ToNorm'],coreFetures=['H4','H3', 'H3.3'])\n",
    "        else: \n",
    "          print ('error')\n",
    "          break\n",
    "        \n",
    "        k[i] = K \n",
    "        print (sample + i,f'; normalized with method {j}')\n",
    "    return k\n",
    "\n",
    "k = normalize_data(k,'k',names)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merged datasets and subsampling\n",
    "create a merged to single dataset\n",
    "1. samples 1245\n",
    "2. samples 12456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size: 1772, new size: 1771\n",
      "original size: 39276, new size: 1771\n",
      "original size: 313781, new size: 1771\n",
      "original size: 63390, new size: 1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size: 313781, new size: 5000\n",
      "original size: 63390, new size: 5000\n",
      "original size: 99457, new size: 5000\n",
      "original size: 57348, new size: 5000\n",
      "original size: 108977, new size: 5000\n",
      "original size: 33196, new size: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size: 1772, new size: 1771\n",
      "original size: 39276, new size: 1771\n",
      "original size: 313781, new size: 1771\n",
      "original size: 63390, new size: 1771\n",
      "original size: 99457, new size: 1771\n",
      "original size: 57348, new size: 1771\n",
      "original size: 108977, new size: 1771\n",
      "original size: 33196, new size: 1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n",
      "/home/yishai/breast_cancer/functions/usefull_functions.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  k_append = k_append.append(K, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for i, K in k.items():\n",
    "    k[i]['by_sample'] = float(i)\n",
    "    names[i]['ind'] = k[i]['by_sample']\n",
    "\n",
    "# merged dataset is normalize with H3 and plot by its own fig\n",
    "names['norm_type'].append(2)\n",
    "names['figures'].append(4)\n",
    "\n",
    "\n",
    "uncommonFeatures1245 = ['NCad','ECad','panKeratin',  'p53', 'ZEB1' ]\n",
    "uncommonFeatures456789 = ['panKeratin',  'p53', 'ZEB1' ]\n",
    "uncommonFeatures12456789 = ['NCad','ECad','panKeratin',  'p53', 'ZEB1']\n",
    "\n",
    "# remove the uncommonFeatures from the  mutual list, create data-dict without uncommonFeatures and append into single dataset\n",
    "names['1245']  = removeFeatures(names['all'].copy(),uncommonFeatures1245)\n",
    "k['1245'],names['1245']['ind'] = createAppendDataset(names['1245'],getAppendDict(k,['1','2','4','5'],uncommonFeatures1245 ),n=1771)\n",
    "\n",
    "names['456789']  = removeFeatures(names['all'].copy(),uncommonFeatures456789)\n",
    "k['456789'],names['456789']['ind']= createAppendDataset(names['456789'],getAppendDict(k,['4','5','4.1','7','8','11'],uncommonFeatures456789 ),n=5000)\n",
    "\n",
    "names['12456789']  = removeFeatures(names['all'].copy(),uncommonFeatures12456789)\n",
    "k['12456789'],names['12456789']['ind']= createAppendDataset(names['12456789'],getAppendDict(k,['1','2','4','5','4.1','7','8','11'],uncommonFeatures12456789 ),n=1771)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save pre-scaled data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, K in k.items():\n",
    "#     try:\n",
    "#       del dict;dict ={}\n",
    "#     except:\n",
    "#         dict ={}\n",
    "#     dict['k'] = K\n",
    "#     pickle_dump('k'+i+'_prescaled_dict', dict,dir_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data \n",
    "\n",
    "using mean, std (whiten data) - achieve std close to 1 mean close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:21:03.888212Z",
     "start_time": "2022-12-11T11:21:03.847807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 scaled\n",
      "k2 scaled\n",
      "k4 scaled\n",
      "k5 scaled\n",
      "k4.1 scaled\n",
      "k7 scaled\n",
      "k8 scaled\n",
      "k11 scaled\n",
      "k1245 scaled\n",
      "k456789 scaled\n",
      "k12456789 scaled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, K in k.items():\n",
    "\n",
    "    k[i] = scale_data(K)\n",
    "    print (f'k{i} scaled')\n",
    "    # print(K.std().to_frame().T)\n",
    "# the index numbers are unfortunately passes into scaling and norm\n",
    "# after scaling rturn the unscled index numbers\n",
    "for i, K in k.items():\n",
    "    k[i]['by_sample'] = names[i]['ind']\n",
    "    names[i]['sampleInd'] = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:21:10.287898Z",
     "start_time": "2022-12-11T11:21:07.437490Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if visualize:\n",
    "    plot_hist(k,names['all']['NamesAll'],names['figures'],settings,\n",
    "        func = sns.kdeplot,title = 'Normalized + Scaled',Figname = '2_Hist_normalized_scaled_' )     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsample original data; verify n<=5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '4', '5', '4.1', '7', '8', '11']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if subsample:\n",
    "    for i in list(k.keys())[:8]:\n",
    "        k[i] = subsample_k(k[i],n=5000)\n",
    "\n",
    "list(k.keys())[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other\n",
    "Save data to file (pickle)\n",
    "\n",
    "convert images to pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1; samples =  1772 , fetures =  38\n",
      "k2; samples =  39276 , fetures =  38\n",
      "k4; samples =  313781 , fetures =  39\n",
      "k5; samples =  63390 , fetures =  39\n",
      "k4.1; samples =  99457 , fetures =  39\n",
      "k7; samples =  57348 , fetures =  39\n",
      "k8; samples =  108977 , fetures =  39\n",
      "k11; samples =  33196 , fetures =  39\n",
      "k1245; samples =  7084 , fetures =  34\n",
      "k456789; samples =  30000 , fetures =  36\n",
      "k12456789; samples =  14168 , fetures =  34\n",
      "k1 ; saved to file\n",
      "k2 ; saved to file\n",
      "k4 ; saved to file\n",
      "k5 ; saved to file\n",
      "k4.1 ; saved to file\n",
      "k7 ; saved to file\n",
      "k8 ; saved to file\n",
      "k11 ; saved to file\n",
      "k1245 ; saved to file\n",
      "k456789 ; saved to file\n",
      "k12456789 ; saved to file\n",
      "total run time = 29.793874500000015\n"
     ]
    }
   ],
   "source": [
    "for i, K in k.items():\n",
    "  print ('k'+i+ '; samples = ', len(K), ', fetures = ', len(K.columns))\n",
    "\n",
    "for i, K in k.items():\n",
    "    try:\n",
    "      del dict;dict ={}\n",
    "    except:\n",
    "        dict ={}\n",
    "    dict['k'] = K\n",
    "    pickle_dump('k'+i+'_dict', dict,dir_data)\n",
    "    \n",
    "    del dict;dict ={}\n",
    "    dict = names[i]\n",
    "    # dict['all'] = names['all']\n",
    "    pickle_dump('k'+i+'_names_dict', dict,dir_data)\n",
    "    print('k'+i,'; saved to file')\n",
    "\n",
    "\n",
    "\n",
    "end = time.process_time()\n",
    "print ('total run time =', end-start )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:05:54) \n[GCC 11.2.0]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "47461faa88aa067695cc57f541ef1d2dc4d6f921b9b537a7f257f46bf46d112f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
