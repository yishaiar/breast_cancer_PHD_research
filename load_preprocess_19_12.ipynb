{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir=\"~/Desktop/biology/breast_cancer/data/\"\n",
    "# ubunto:\n",
    "# old samples\n",
    "dir1=\"~/Dropbox/CyTOF_Breast/Kaplan_1st/\"\n",
    "# new samples\n",
    "dir2 = '~/Dropbox/CyTOF_Breast/Kaplan_2nd/data_afterGating/processed data/'\n",
    "# plot dir\n",
    "dir_plots = 'Plots_preproccess/'\n",
    "\n",
    "# home:\n",
    "# old samples\n",
    "# dir1=\"C:/Users/yishai/Dropbox/CyTOF_Breast/Kaplan_1st/\"\n",
    "# new samples\n",
    "# dir2 = \"C:/Users/yishai/Dropbox/CyTOF_Breast/Kaplan_2nd/data_afterGating/processed data/\"\n",
    "# plot dir\n",
    "# dir_plots = 'C:/Users/yishai/Desktop/biology/breast_cancer/Plots'\n",
    "\n",
    "# plots:\n",
    "    # create visualization\n",
    "visualize = True\n",
    "    # show figures\n",
    "show = False\n",
    "\n",
    "subsample = False\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig(\"test.svg\", format=\"svg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "envirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:54.700552Z",
     "start_time": "2022-12-11T11:15:54.680091Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 22 20:09:58 2021\n",
    "\n",
    "@author: ronguy\n",
    "\"\"\"\n",
    "import time \n",
    "start = time.process_time()\n",
    "import os\n",
    "\n",
    "import sys\n",
    "from IPython.display import Image, display\n",
    "# from tqdm import tqdm_notebook,tqdm\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "# import matplotlib.patches as  mpatches\n",
    "plt.rcParams[\"figure.figsize\"] = (5.0, 4.0)  # Set default size of plots.\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 180) #according to screen width\n",
    "# from pandas.core.base import PandasObject\n",
    "# PandasObject.view = view #allows view meth pd.view\n",
    "\n",
    "from scipy import signal, stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, DBSCAN, MiniBatchKMeans\n",
    "# from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "# from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "# from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from lmfit import minimize, Parameters\n",
    "# from umap import UMAP\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "# import schist as scs\n",
    "\n",
    "# import networkx as nx\n",
    "\n",
    "# from castle.common import GraphDAG\n",
    "# from castle.metrics import MetricsDAG\n",
    "# from castle.datasets import IIDSimulation, DAG\n",
    "# from castle.algorithms import PC,Notears,GOLEM,ANMNonlinear,DirectLiNGAM,ICALiNGAM,NotearsLowRank\n",
    "# import notears.notears as notears\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.geometry.polygon import Polygon\n",
    "\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# from statsmodels.graphics._regressionplots_doc import _plot_influence_doc\n",
    "# from statsmodels.regression.linear_model import OLS\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "\n",
    "from usefull_functions import *\n",
    "from functions import *\n",
    "from normalization import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "folderExists(dir_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature names (Participating panel)\n",
    "\n",
    "\n",
    "Received CyTOF data is assumed to be only of intact single and alive cells  \n",
    "\n",
    "each sample matrix with high dimensionality feature space (NamesAll) and without duplicate samples\n",
    "\n",
    "experiment2 without: 'p53', 'ZEB1', \n",
    "experiment1 without: 'NCad','ECad','panKeratin'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:54.721783Z",
     "start_time": "2022-12-11T11:15:54.701446Z"
    }
   },
   "outputs": [],
   "source": [
    "features = {}\n",
    "features['NamesAll'] = [  \n",
    "            'CD45','H4','H3', 'H3.3','NCad','ECad','panKeratin', 'K5', 'EpCam', 'H3K27me2', 'p53', 'EZH2', 'H3K4me3', 'gH2AX','aSMA','H3K36me2','H3K4me1','H3K9me2','H4K16ac',\n",
    "            'H2Aub', 'Vimentin', 'H3K64ac', 'BMI-1', 'ZEB1',  'H3K27ac', 'H4K20me3', 'ER', 'CD49f', 'H3K36me3', 'CD24',\n",
    "            'GATA3', 'H3K27me3', 'H3K9ac', 'H3K9me3', 'CD44', 'Ki67', 'K8-18', 'H3S28p', 'Ir_DNA2', 'Live_Dead',\n",
    "        ]\n",
    "\n",
    "# extra cellular are outside the cell - except them everything is noramalized (in group \"ToNorm\")\n",
    "features['ToNorm'] = [    \n",
    "            'H4','H3', 'H3.3','panKeratin', 'K5', 'H3K27me2', 'p53', 'EZH2', 'H3K4me3', 'gH2AX', 'aSMA', 'H3K36me2', 'H3K4me1', 'H3K9me2',\n",
    "            'H4K16ac', 'H2Aub', 'Vimentin', 'H3K64ac', 'BMI-1', 'ZEB1', 'H3K27ac', 'H4K20me3',\n",
    "            'ER', 'H3K36me3', 'GATA3', 'H3K27me3', 'H3K9ac', 'H3K9me3', 'Ki67', 'K8-18', 'H3S28p',\n",
    "        ]\n",
    "features['CellIden'] = [  \n",
    "            'CD45', 'K5', 'EpCam', 'aSMA', 'Vimentin', 'ZEB1', 'ER', 'CD49f', 'CD24', 'GATA3', 'CD44', 'K8-18',\n",
    "            'Ki67','p53',\n",
    "            'NCad','ECad','panKeratin',\n",
    "        ]\n",
    "# everything that is not cell identity\n",
    "features['EpiCols'] = [   \n",
    "            'H4','H3', 'H3.3', 'H3K27me2', 'H3K4me3', 'H3K36me2', 'H3K4me1', 'H3K9me2', 'H4K16ac', 'H2Aub', 'H3K64ac',  \n",
    "            'H3K27ac', 'H4K20me3', 'BMI-1','EZH2','gH2AX',\n",
    "            'H3K36me3', 'H3K27me3', 'H3K9ac', 'H3K9me3', 'H3S28p'\n",
    "        ]\n",
    "\n",
    "# intra cellular??\n",
    "features['NMS'] = [       \n",
    "            'CD45', 'K5', 'EpCam', 'H3K27me2', 'p53', 'EZH2', 'H3K4me3', 'gH2AX', 'aSMA', 'H3K36me2', 'H3K4me1',\n",
    "            'H3K9me2', 'H4K16ac', 'H2Aub', 'Vimentin', 'H3K64ac', 'BMI-1', 'ZEB1', 'H3K27ac', 'H4K20me3', 'ER',\n",
    "            'CD49f', 'H3K36me3', 'CD24', 'GATA3', 'H3K27me3', 'H3K9ac', 'H3K9me3', 'CD44', 'Ki67', 'K8-18', 'H3S28p',\n",
    "        ]\n",
    "\n",
    "features = removeFeatures(features.copy(),features =['Ir_DNA2', 'Live_Dead'])\n",
    "# diffrence of features1\n",
    "features1 = removeFeatures(features.copy(),features =['NCad','ECad','panKeratin',])\n",
    "# diffrence of features2\n",
    "features2 = removeFeatures(features.copy(),features =['p53','ZEB1'])\n",
    "\n",
    "\n",
    "    #  'H3S28p','p53', 'EZH2', 'gH2AX', 'BMI-1', 'Ki67', 'Ir_DNA2', 'Live_Dead'\n",
    "\n",
    "\n",
    "names = {}\n",
    "names['figures'] = [1,1,2,2,2]\n",
    "\n",
    "names['1'] = features1\n",
    "names['2'] = features1\n",
    "names['3'] = features2\n",
    "names['4'] = features2\n",
    "names['5'] = features2\n",
    "names['all'] = features\n",
    "del features;del features1; del features2\n",
    "\n",
    "\n",
    "def test_fetures(NamesAll,CellIden,EpiCols):\n",
    " \n",
    "  new_NamesAll = CellIden+EpiCols\n",
    "  test1 = all(item in new_NamesAll for item in NamesAll)\n",
    "  if not test1:\n",
    "    for i in new_NamesAll:\n",
    "      NamesAll.remove(i)\n",
    "      \n",
    "    print(NamesAll)\n",
    "    \n",
    "  test2 = not (any(item in CellIden for item in EpiCols))\n",
    "  return test1*test2\n",
    " \n",
    " \n",
    "\n",
    "# verify:\n",
    "#   CellIden +EpiCols = NamesAll\n",
    "#   no feature is both in CellIden and EpiCols\n",
    "for i, name in names.items():\n",
    "  try:\n",
    "    NamesAll = name['NamesAll'].copy()\n",
    "    CellIden = name['CellIden'].copy()\n",
    "    EpiCols = name['EpiCols'].copy()\n",
    "    if test_fetures(NamesAll,CellIden,EpiCols) != 1:\n",
    "      print('error in sample', i)\n",
    "  except:\n",
    "    pass\n",
    "print ('features are correct!')\n",
    "  \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from csv, and store in dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:56.012810Z",
     "start_time": "2022-12-11T11:15:54.722716Z"
    }
   },
   "outputs": [],
   "source": [
    "K1=pd.read_csv(dir1+\"BCK-01_noaf_18Sep2022_01_0.fcs_file_internal_comp_residual.csv\")\n",
    "K2=pd.read_csv(dir1+\"BCK-02_noaf_18Sep2022_01_0.fcs_file_internal_comp_residual.csv\")\n",
    "\n",
    "# new features - without:p53, zeb1, with: pankeratin, ecad, ncad \n",
    "\n",
    "K3=pd.read_csv(dir2+\"export_BCK03_noaf_23Nov2022_01_0_final_cells - processed.csv\")\n",
    "K4=pd.read_csv(dir2+\"export_BCK04_noaf_23Nov2022_02_0_final_cells - processed.csv\")\n",
    "K5=pd.read_csv(dir2+\"export_BCK05_noaf_23Nov2022_01_0_final_cells - processed.csv\")\n",
    "\n",
    "# later analysis k6 with duplicates\n",
    "# K6=pd.read_csv(dir2+\"export_BCK05_noaf_23Nov2022_01_0_final_cells.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "k={}\n",
    "k['1'] = K1[names['1']['NamesAll']]\n",
    "k['2'] = K2[names['2']['NamesAll']]\n",
    "\n",
    "k['3'] = K3[names['3']['NamesAll']]\n",
    "k['4'] = K4[names['4']['NamesAll']]\n",
    "k['5'] = K5[names['5']['NamesAll']]\n",
    "\n",
    "del K1;del K2;del K3;del K4;del K5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:56.672977Z",
     "start_time": "2022-12-11T11:15:56.013751Z"
    }
   },
   "outputs": [],
   "source": [
    "if show:\n",
    "  for i, K in k.items():\n",
    "      print ('k'+i)\n",
    "      print ('\\n')\n",
    "  #     print(K.head(3)) #see samples\n",
    "      print(K.describe()) #mean,std, max,min, q25,q50,q75\n",
    "      print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# gating and transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gating - fix fluidigm gating result; In-gate and outlier removal (Samples with low number of events)\n",
    "\n",
    "Samples with low number of events are discarded (outliers) - remove outlier 99.99% from all\n",
    "\n",
    "In gate to achieve good normalization - gate on H3.3/H4 was too low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:57.286122Z",
     "start_time": "2022-12-11T11:15:56.691586Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Gate(data,name,GateColumns):\n",
    "    ddf=data.copy()\n",
    "    print(name, 'gating on: ', GateColumns)\n",
    "    print(\"Initial number of samples: \",len(ddf))\n",
    "    # index of gating values ddf[['H3.3','H4']] larger than  Core gate value(5) \n",
    "    ind = (ddf[GateColumns]>5).all(axis=1)   \n",
    "    ddf=ddf[ind]\n",
    "    print(\"Core Gate: \",len(ddf))\n",
    "    \n",
    "    # index of quantile 99.99% gating values (remove outliers)\n",
    "    quantile = np.quantile(ddf,0.9999,axis=0)\n",
    "    outliers = ddf[(ddf>quantile).any(axis=1)]\n",
    "    ddf=ddf[(ddf<quantile).all(axis=1)]\n",
    "    print(\"Outlier Gate: \",len(ddf), ', samples removed:', len(outliers))\n",
    "    # outliers distribution is not in a specific feature:\n",
    "    \n",
    "    # outliers [ outliers>quantile] = None\n",
    "    # print(outliers.head(35))\n",
    "    data=ddf.copy()\n",
    "    del ddf\n",
    "    return data\n",
    "\n",
    "\n",
    "GateColumns=['H3.3','H4']#,'H3']#,'H3']\n",
    "for [i, K] , j in zip(k.items(), names['figures']):\n",
    "  \n",
    "    if j==1:\n",
    "      k[i] = Gate(K,'k' + i,['H3.3','H4'])\n",
    "      print ('k' + i, ': gated')\n",
    "    if j==2:\n",
    "      k[i] = Gate(K,'k' + i,['H3','H3.3','H4'])\n",
    "      print (f'k{i}: gated with method {j}')\n",
    "    \n",
    "\n",
    "# k_gate = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " arcsinh data transformation\n",
    "  \n",
    "  transformation (semi log scaling): scale argument = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:57.623862Z",
     "start_time": "2022-12-11T11:15:57.287245Z"
    }
   },
   "outputs": [],
   "source": [
    "def arcsinh_transform(unscaled_data, scale=5):\n",
    "    scaled_data=np.arcsinh(unscaled_data.copy()/scale)\n",
    "    return scaled_data\n",
    "    \n",
    "\n",
    "for i, K in k.items():\n",
    "    k[i] = arcsinh_transform(K)\n",
    "    print ('k' + i,'; arcsinh transformed')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:15:58.179581Z",
     "start_time": "2022-12-11T11:15:57.625091Z"
    }
   },
   "outputs": [],
   "source": [
    "if show:\n",
    "  for i, K in k.items():\n",
    "      print ('k'+i)\n",
    "      \n",
    "      # print(K.head(3)) #see samples\n",
    "      print(K.describe()) #mean,std, max,min, q25,q50,q75\n",
    "      print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualization\n",
    "\n",
    "arcsinh probability density plot - analysis of herogeneity (division to multiple populations), results:\n",
    "\n",
    "cd45 - we want only the negative population\n",
    "\n",
    "2 close populations - epcam, vimentin,cd49f\n",
    "\n",
    "2 far populations - cd44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:16:03.414227Z",
     "start_time": "2022-12-11T11:15:58.180669Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Kernel Distribution Estimation Plot (kdeplot) is the probability density function plot\n",
    "# # can plot for the univariate (single variable) or multiple variables altogether. \n",
    "# # i.e y = probability, x = feature value after arcsinh transformation (can be also negative)\n",
    "if visualize:\n",
    "  interst=[  'CD45','CD44', 'EpCam', 'Vimentin', 'CD49f','CD45','H4','H3', 'H3.3','NCad','ECad','panKeratin',]\n",
    "  plot_hist(k,interst,names['figures'],dir_plots,show,\n",
    "          func = sns.kdeplot,title = 'ArcSinh Unnormalized',figname = '1_Hist_ArcSinh_Unnormalized_' )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:16:40.368500Z",
     "start_time": "2022-12-11T11:16:03.415174Z"
    }
   },
   "outputs": [],
   "source": [
    "if visualize:\n",
    "  plot_hist(k,names['all']['NamesAll'],names['figures'],dir_plots,show,\n",
    "            func = sns.kdeplot,title = 'ArcSinh Unnormalized',figname = '1_Hist_ArcSinh_Unnormalized_' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split CD45 neg \n",
    "\n",
    "the only interesting population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:16:45.618105Z",
     "start_time": "2022-12-11T11:16:40.370107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kernel density estimation is the random variable's probability density function (PDF) estimatation\n",
    "def inverse_PDF(K,i,feature, min_x = 'None'):\n",
    "  \n",
    "    # get data value for data with highest probability (peak)\n",
    "      \n",
    "  kernel = stats.gaussian_kde(K[feature])\n",
    "  r=np.linspace(K[feature].min(),5,100)\n",
    "  if min_x =='None':\n",
    "    # avoid zero division using max; # inv_data = 1/np.maximum(1e-9,kernel(r))\n",
    "    inv_data = 1/kernel(r)\n",
    "\n",
    "    # minima : use builtin function fo find (min) peaks (use inversed data)\n",
    "    # get index of input vector peaks, widths input - expected width of peaks of interest\n",
    "    # min_peakind = signal.find_peaks_cwt(inv_data,np.arange(0.02,20,0.001))\n",
    "    min_peakind = signal.find_peaks_cwt(inv_data,np.arange(1,100))\n",
    "\n",
    "    min_x = r[min_peakind[0]]\n",
    "  KCD45Neg = K[K[feature]<min_x].copy()\n",
    "  min_y = kernel(min_x)[0]\n",
    "  return KCD45Neg ,min_x, min_y\n",
    "\n",
    "\n",
    "\n",
    "kCD45Neg ,min_x, min_y = {},{},{}\n",
    "for i, K in k.items():\n",
    "    \n",
    "    try:\n",
    "      kCD45Neg[i], min_x[i],min_y[i] = inverse_PDF(K,i,'CD45')\n",
    "      print ('k' + i+'; CD45 neg seperated')\n",
    "      print('value with highest *inverse* probability:', min_x[i])\n",
    "    except:\n",
    "        print('k' + i,';minima not found')\n",
    "print('manual')        \n",
    "kCD45Neg['4'], min_x['4'],min_y['4'] = inverse_PDF(k['4'],'4','CD45',min_x = 0.5)\n",
    "print ('k4; CD45 neg seperated')\n",
    "print('value with highest *inverse* probability:', min_x['4'])\n",
    "\n",
    "if visualize:\n",
    "  for i, K in k.items():\n",
    "    plt.figure(figsize=(9,3))\n",
    "    plt.title(f'K{i} ; limit = {np.round(min_x[i],4)}')\n",
    "    sns.kdeplot(K['CD45'])\n",
    "    plt.scatter(min_x[i],min_y[i])\n",
    "    plt.savefig(dir_plots+'/K'+i+'_cd45_split.svg', format=\"svg\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    # plt.savefig(dir_plots+'/K'+i+'_cd45_split.png',dpi=200,bbox_inches='tight')\n",
    "del min_x; del min_y\n",
    "\n",
    "# # ThK1={'CD45': 1.8686868686868687}\n",
    "# # ThK2={'CD45': 2.1717171717171717}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:20:23.595179Z",
     "start_time": "2022-12-11T11:20:23.218312Z"
    }
   },
   "outputs": [],
   "source": [
    "if visualize:\n",
    "  colors = cm.rainbow(np.linspace(0, 1, len (k.keys())))\n",
    "  fig, ax = plt.subplots(1,2,figsize=(10,3))\n",
    "  for i, K in k.items(): \n",
    "    #   \n",
    "    j =  names['figures'][int(i)-1]-1 \n",
    "    sns.histplot(K.CD45,color=colors[int(i)-1],label='T'+i,stat='density',element='step',fill=False,ax = ax[j])\n",
    "    ax[j].legend(loc='upper center',bbox_to_anchor=(1,1))\n",
    "    ax[j].set_yscale('log')\n",
    "    ax[j].title.set_text('cd45 split histplot')\n",
    "  plt.savefig(dir_plots+'cd45_split_histplot.svg', format=\"svg\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "  fig, ax = plt.subplots(1,2,figsize=(12,3))\n",
    "  for [i, K],[h, KCD45Neg] in zip( k.items(),kCD45Neg.items()):\n",
    "      j =  names['figures'][int(i)-1]-1 \n",
    "      sns.kdeplot(K.CD45,color=colors[int(i)-1],label='T'+i,ax = ax[j])\n",
    "      sns.kdeplot(K.CD45,color=colors[int(i)-1],ls='--',label='T'+i+' CD45-',ax = ax[j])\n",
    "      ax[j].legend(loc='upper center',bbox_to_anchor=(1,1))\n",
    "      ax[j].set_yscale('log')\n",
    "      ax[j].title.set_text('cd45 split kdeplot')\n",
    "  plt.savefig(dir_plots+'cd45_split_kdeplot.svg', format=\"svg\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue only with CD45 neg population\n",
    "\n",
    "1 - delete cd45+ population and continue with k  = kCD45Neg\n",
    "\n",
    "2 - delete cd45 feature from data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del k\n",
    "k = kCD45Neg.copy()\n",
    "del kCD45Neg\n",
    "\n",
    "for i, K in k.items():\n",
    "  K.drop( columns='CD45')\n",
    "  k[i] = K\n",
    "  \n",
    "  # remove from features lists(names)\n",
    "  N = names[i]\n",
    "  for j, sublist in N.items():\n",
    "    try:\n",
    "      sublist.remove('CD45')\n",
    "    except:\n",
    "      pass\n",
    "    N[j] = sublist\n",
    "  names[i] = N\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normalize using new method on all intercellular markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 step normalization:\n",
    "\n",
    "1- normalize gardient (TBD)\n",
    "\n",
    "1- normalize using core\n",
    "\n",
    "insight: since its the minima multiple rus with same effect as one run\n",
    "\n",
    "note: features to norm (i.e names[i]['ToNorm']) are different on each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:20:36.437744Z",
     "start_time": "2022-12-11T11:20:36.184723Z"
    }
   },
   "outputs": [],
   "source": [
    "# if visualize:\n",
    "#   for i, K in k.items():\n",
    "#     print ('k' + i,', initial std:')\n",
    "#     print(K.std().to_frame().T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(k,sample,names):\n",
    "    for [i, K] , j in zip(k.items(), names['figures']):\n",
    "        \n",
    "        # FIRST STEP - normalize_gardient by core \n",
    "        # SECOND STEP - normalize ToNorm fetures by the core features ['H3.3','H4']\n",
    "        \n",
    "        if j==1:\n",
    "          K=NormalizeNew2(K,names[i]['ToNorm'])\n",
    "          K = Mean_Core_normalization(K, names[i]['ToNorm'],coreFetures=['H3.3','H4'])\n",
    "        elif j==2:\n",
    "          K=NormalizeNew(K,names[i]['ToNorm'])\n",
    "          K = Mean_Core_normalization(K, names[i]['ToNorm'],coreFetures=['H4','H3', 'H3.3'])\n",
    "        else: \n",
    "          print ('error')\n",
    "          break\n",
    "        \n",
    "        k[i] = K \n",
    "        print (sample + i,f'; normalized with method {j}')\n",
    "    return k\n",
    "k = normalize_data(k,'k',names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data \n",
    "\n",
    "using mean, std (whiten data) - achieve std close to 1 mean close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:21:03.888212Z",
     "start_time": "2022-12-11T11:21:03.847807Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, K in k.items():\n",
    "    k[i] = scale_data(K)\n",
    "    # print(K.std().to_frame().T)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:21:10.287898Z",
     "start_time": "2022-12-11T11:21:07.437490Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if visualize:\n",
    "  plot_hist(k,names['all']['NamesAll'],names['figures'],dir_plots,show,\n",
    "            func = sns.kdeplot,title = 'Normalized + Scaled',figname = '2_Hist_normalized_scaled_' )     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsample data\n",
    "\n",
    "verify; n<=5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T11:17:29.951256Z",
     "start_time": "2022-12-11T11:17:29.780204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# if subsample:\n",
    "#   k = subsample_data(k,'k',n=5000)\n",
    "# else:\n",
    "  # for i, K in k.items():\n",
    "  #   print ('k'+i+ '; samples = ', len(K), ', fetures = ', len(K.columns))\n",
    "    \n",
    "for i, K in k.items():\n",
    "  print ('k'+i+ '; samples = ', len(K), ', fetures = ', len(K.columns))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other\n",
    "Save data to file (pickle)\n",
    "\n",
    "convert images to pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, K in k.items():\n",
    "  dict ={}\n",
    "  dict['k'] = K\n",
    "  dict['names'] = names[i]\n",
    "  dict['all'] = names['all']\n",
    "  pickle_dump('k'+i+'_dict', dict)\n",
    "  print('k'+i,'; saved to file')\n",
    "\n",
    "\n",
    "\n",
    "del k;  del names\n",
    "\n",
    "# imList2pdf(dir_plots)\n",
    "\n",
    "\n",
    "end = time.process_time()\n",
    "print ('total run time =', end-start )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "47461faa88aa067695cc57f541ef1d2dc4d6f921b9b537a7f257f46bf46d112f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
