{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import numpy as np\n",
    "# remove avx warning:\n",
    "# I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "# To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "\n",
    "from pandas import DataFrame,Series\n",
    "from usefull_functions_new import random_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load test data (if not loaded from outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if IS_MASTER exists, this variable will only exist if it's being called by MASTER notebook.\n",
    "# if it does not exist, set it to False\n",
    "\n",
    "\n",
    "\n",
    "try: use_MASTER\n",
    "except: use_MASTER = False\n",
    "\n",
    "if not use_MASTER:\n",
    "    #%run imports.ipynb\n",
    "    from pathlib import Path\n",
    "    from sys import path\n",
    "    \n",
    "    #pickle,sys\n",
    "    home = str(Path.home())\n",
    "    save_add = f'{home}/Dropbox/CyTOF_Breast/data_yishai/'\n",
    "    \n",
    "    #add the path were the functions are and load the small dataset (used for testing) and config data\n",
    "    path.append(f'{home}/Desktop/breast_cancer_PHD_research/functions/')\n",
    "    # with open(f'{save_add}/Dropbox/CyTOF_Breast/data_yishai/default_data.p', 'rb') as f:\n",
    "    #   [df,config] = pickle.load(f)\n",
    "    with open(f'{save_add}default_sample.json', \"r\") as f:\n",
    "        df = DataFrame.from_dict(json.load(f)).reset_index(drop=True)\n",
    "    with open(f'{save_add}default_config.json', \"r\") as f:\n",
    "        config = json.load(f) \n",
    "    del f, home,save_add\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import numpy as np\n",
    "# remove avx warning:\n",
    "# I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "# To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "\n",
    "from pandas import DataFrame,Series\n",
    "\n",
    "from plot_functions_new import class_colors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define classification class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from metrics_and_dataset_utils import *  \n",
    "from xg_shap import Shap, fitXGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_MASTER:\n",
    "    samples = Series(df['samp'])\n",
    "    # .strdrop_duplicates()\n",
    "    \n",
    "    LEN = int(df.shape[0]/2)\n",
    "    labels = Series(np.random.randint(-1,4,LEN),index = df.index[:LEN])#random labels for testing\n",
    "    \n",
    "    # the labels of each single sample clustering\n",
    "    # sample_labels = Series(np.random.randint(-1,5,df.shape[0]),index = df.index)#random labels for testing\n",
    "    # sample_labels.loc[0],samples.loc[0]=-99,4.0#add error to test error handling\n",
    "    classes = Series(random_list(arr = ['Unknown', 'Noise' ,'Luminal' ,'Basal-like' ,'Cycling'],LEN = LEN ),index = df.index[:LEN])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into the train-test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-test data split using random split\n",
      "train-test data split using sample indexes: train-[4, 7, 8, 14],test-[5, 11, 13, 15, 17, 18, 19, 20]\n",
      "train-test data split using sample indexes: train-[4],test-[4.1]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = createDataset(df[config['features']].copy(),labels.copy())\n",
    "X_train, X_test, y_train, y_test = createDataset(df[config['features']].copy(),labels.copy(),samples.copy(),train_samples = [4,7,8,14],test_samples = [  5,11,13,15,17,18,19,20])\n",
    "X_train, X_test, y_train, y_test = createDataset(df[config['features']].copy(),labels.copy(),samples.copy(),train_samples = [4],test_samples = [  4.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier fit, calculate metrics & shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create new classes: \n",
    "1. classes - ['Unknown' 'Noise' 'Cycling' 'Luminal' 'Basal-like']\n",
    "2. classes1 - ['Cycling' 'Lum&Basal']\n",
    "3. xlasses2 - ['Luminal' 'Basal-like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basal-like', 'Cycling', 'Luminal', 'Noise', 'Unknown']\n",
      "['Cycling', 'Lum&Basal']\n",
      "['Basal-like', 'Luminal']\n"
     ]
    }
   ],
   "source": [
    "classes1 = classes[(classes=='Basal-like')|(classes=='Luminal')|(classes=='Cycling')].copy()\n",
    "classes1[(classes=='Basal-like')|(classes=='Luminal')] = 'Lum&Basal'\n",
    "classes2 = classes[(classes=='Basal-like')|(classes=='Luminal')].copy()\n",
    "print(sorted(classes.unique()))\n",
    "print(sorted(classes1.unique()))\n",
    "print(sorted(classes2.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original classes (all 3 & noise and unknown); XGBClassifier fit, calculate metrics & shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop df rows without label (drop points without label) and split randomly\n",
    "X_train, X_test, y_train, y_test = createDataset(df[config['features']].copy(),classes.copy())\n",
    "\n",
    "model,label_encoder = fitXGBClassifier(X_train.copy(), y_train.copy())\n",
    "\n",
    "# predict y_test_pred using X_test and inverse transform it back to the original class labels - compare y_test_pred results to y_test\n",
    "accuracy = ClassificationMetrics(y_test,    Series(label_encoder.inverse_transform(model.predict(X_test))))\\\n",
    "                                .plot_all(config['dir_plots'] +'5_'+ config['figname']+'using_'+'all_classes_')\n",
    "\n",
    "Shap(**config).calculate(X_test,model,label_encoder,accuracy,colors = class_colors(),LEN = 1000,\n",
    "                         figname = '5_Shap_' + config['figname']+'using_'+'all_classes_')\n",
    "print(f\"classes accuracy {config['j']}_{config['feautures_ind']}: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lum&Basal_vs_Cycling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop df rows without label (drop points without label) and split randomly\n",
    "X_train, X_test, y_train, y_test = createDataset(df[config['features']].copy(),classes1.copy())\n",
    "\n",
    "model,label_encoder = fitXGBClassifier(X_train.copy(), y_train.copy())\n",
    "\n",
    "# predict y_test_pred using X_test and inverse transform it back to the original class labels - compare y_test_pred results to y_test\n",
    "accuracy = ClassificationMetrics(y_test,    Series(label_encoder.inverse_transform(model.predict(X_test))))\\\n",
    "                                .plot_all(config['dir_plots'] + '5_'+config['figname']+'using_'+'Lum&Basal_vs_Cycling_')\n",
    "\n",
    "Shap(**config).calculate(X_test,model,label_encoder,accuracy,colors = class_colors(),LEN = 1000,\n",
    "                         figname = '5_Shap_' + config['figname']+'using_'+'Lum&Basal_vs_Cycling_')\n",
    "print(f\"classes accuracy {config['j']}_{config['feautures_ind']}: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lum_vs_Basal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop df rows without label (drop points without label) and split randomly\n",
    "X_train, X_test, y_train, y_test = createDataset(df[config['features']].copy(),classes2.copy())\n",
    "\n",
    "model,label_encoder = fitXGBClassifier(X_train.copy(), y_train.copy())\n",
    "\n",
    "# predict y_test_pred using X_test and inverse transform it back to the original class labels - compare y_test_pred results to y_test\n",
    "accuracy = ClassificationMetrics(y_test,    Series(label_encoder.inverse_transform(model.predict(X_test))))\\\n",
    "                                .plot_all(config['dir_plots'] + '5_'+config['figname']+'using_'+'Lum_vs_Basal_')\n",
    "\n",
    "Shap(**config).calculate(X_test,model,label_encoder,accuracy,colors = class_colors(),LEN = 1000,\n",
    "                         figname = '5_Shap_' + config['figname']+'using_'+'Lum_vs_Basal_')\n",
    "print(f\"classes accuracy {config['j']}_{config['feautures_ind']}: {accuracy}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
