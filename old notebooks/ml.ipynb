{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "add = '/home/yishai/Dropbox/CyTOF_Breast/Kaplan_5th/_clusters.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samp</th>\n",
       "      <th>class</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Cycling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>luminal</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>basal-like</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>total</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.1</td>\n",
       "      <td>Cycling</td>\n",
       "      <td>2;5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cycling</td>\n",
       "      <td>3;7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20.0</td>\n",
       "      <td>luminal</td>\n",
       "      <td>0;12;9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20.0</td>\n",
       "      <td>basal-like</td>\n",
       "      <td>8;1;6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>20.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>20.0</td>\n",
       "      <td>total</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    samp         class clusters\n",
       "1    4.0       Cycling        1\n",
       "2    4.0       luminal     rest\n",
       "3    4.0    basal-like        5\n",
       "4    4.0         total        8\n",
       "5    4.1       Cycling      2;5\n",
       "..   ...           ...      ...\n",
       "57  20.0       Cycling      3;7\n",
       "58  20.0       luminal   0;12;9\n",
       "59  20.0    basal-like    8;1;6\n",
       "60  20.0       unknown     rest\n",
       "61  20.0         total       12\n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(add).dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(cls,num = True):\n",
    "    if 'basal' in cls:\n",
    "        return 0 if num else 'basal'\n",
    "    elif 'luminal' in cls:\n",
    "        return 1 if num else 'luminal'\n",
    "    elif 'Cycling' in cls:\n",
    "        return 2 if num else 'Cycling'\n",
    "    elif 'unknown' in cls:\n",
    "        return 3 if num else 'unknown'\n",
    "\n",
    "def class_dict(add,num = True):\n",
    "    dict = {}\n",
    "\n",
    "    df = pd.read_csv(add).dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "\n",
    "    # find total clusters of each sample and drop row from df \n",
    "    s = df['samp'].unique()\n",
    "    t = [int(df[np.asarray(df['samp']==samp) * np.asarray(df['class']=='total')]['clusters']) for samp in s]\n",
    "    df = df[df['class']!='total']\n",
    "\n",
    "\n",
    "    for samp,total_clusters in zip(s,t):#iterate on all samples\n",
    "        total_clusters = np.arange(total_clusters) # all clusters in sample  \n",
    "        samp_clusters = []\n",
    "        for i in df[df['samp']==samp].index:\n",
    "            if 'rest' not in df.loc[i]['clusters'] : \n",
    "                for cluster in np.asarray(df.loc[i]['clusters'].split(';')).astype(int):    \n",
    "                    dict[(samp,cluster)] = df.loc[i]['class']\n",
    "                    samp_clusters.append(cluster)\n",
    "            else:#save index of row with rest info\n",
    "                ind = i\n",
    "        for cluster in [t for t in total_clusters if t not in samp_clusters]:#rest clusters\n",
    "            dict[(samp,cluster)] = df.loc[ind]['class']\n",
    "\n",
    "    for key in dict.keys():\n",
    "        dict[key] = get_class(dict[key],num = num)\n",
    "    return dict\n",
    "    \n",
    "dict = class_dict(add = '/home/yishai/Dropbox/CyTOF_Breast/Kaplan_5th/_clusters.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy data\n",
    "\n",
    "df of all samples without classes; sample and cluster info + featurse\n",
    "data assumed to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "features = list(np.arange(20))#generic features for algorithm\n",
    "# ------------------\n",
    "# actual data\n",
    "df = pd.read_csv(add)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df = df.dropna(axis=0, how='all')\n",
    "samp_nums = [4, 4.1, 5, 7, 7.1, 8, 8.1, 11, 13, 14, 15, 17, 18, 19, 20]\n",
    "n = len(samp_nums)\n",
    "samp_total_clusters = [int(df[np.asarray(df['samp']==samp) * np.asarray(df['class']=='total')]['clusters']) for samp in samp_nums]\n",
    "# ----------\n",
    "samples = pd.DataFrame(index = np.arange(data_size),columns = ['sample','cluster']+features)#generate data\n",
    "\n",
    "\n",
    "for i in samples.index:\n",
    "    ind = i%n\n",
    "    # samp = \n",
    "    samples.loc[i,'sample'] = samp_nums[ind]\n",
    "    # tot = t[ind]\n",
    "    samples.loc[i,'cluster'] = np.random.randint(samp_total_clusters[ind], size=1)[0]#random cluster for sample\n",
    "for f in features:\n",
    "    samples[f] = np.random.normal(loc = 0,scale = 1,size = samples.shape[0])#random data    \n",
    "\n",
    "samples_ = samples.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split train test, add class, drop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class         0         1         2         3         4         5  \\\n",
      "0         0  0.528333 -0.474545 -1.276129 -0.152025  0.268125  0.175778   \n",
      "15        0  1.250816 -0.054959  0.287521  0.579007  1.277651  1.277733   \n",
      "30        1 -0.532566 -0.838210 -0.525335  0.709498 -1.680021  0.844800   \n",
      "45        2 -0.260084 -2.456607  0.416544 -1.548655  1.143665 -0.054029   \n",
      "60        0 -0.523983 -0.043487 -0.883347 -1.743818 -0.421359  0.027362   \n",
      "...     ...       ...       ...       ...       ...       ...       ...   \n",
      "9930      0  2.268972  0.991594 -0.613731  1.826613 -0.244207  0.011415   \n",
      "9945      0 -0.772557  0.725169 -0.460429 -1.405410 -2.106354 -0.560215   \n",
      "9960      0  0.544713  1.800990 -1.471888 -2.234235 -0.798046 -0.399533   \n",
      "9975      2 -0.040874 -0.558414 -0.031228 -0.481324 -0.406753 -0.873267   \n",
      "9990      2 -0.368738  0.459806 -0.104493  0.298066  0.613261  1.160878   \n",
      "\n",
      "             6         7         8  ...        10        11        12  \\\n",
      "0    -0.544514  1.184763 -0.039807  ...  0.267896 -0.997449  0.467841   \n",
      "15   -2.087530 -0.646308  0.215717  ... -0.626670 -0.429175 -1.284411   \n",
      "30   -0.759165  0.830650  0.605814  ...  0.468797  1.603406 -0.605739   \n",
      "45    0.281721  2.015813 -0.762296  ... -1.748383 -0.283798 -0.629472   \n",
      "60    1.179021  0.017698 -0.951466  ... -1.673435 -0.110657 -0.456436   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "9930 -0.462993 -0.409462  1.588173  ...  0.209761 -0.658982  0.683642   \n",
      "9945 -1.472306  1.002657 -0.712697  ...  0.158558  2.692144  1.487261   \n",
      "9960 -0.224053 -1.130526 -0.178817  ... -1.015529 -0.480687 -0.663355   \n",
      "9975 -1.629954 -0.903262  0.939126  ...  0.979765 -0.182544  0.558651   \n",
      "9990  0.662776  1.273577 -0.028120  ...  0.237689  1.042174 -0.119060   \n",
      "\n",
      "            13        14        15        16        17        18        19  \n",
      "0    -1.865868 -0.475527  1.137736  0.506775 -0.867223  0.718730  0.187857  \n",
      "15    1.701815  1.431807  1.103109  0.452159 -0.993299 -1.060074  0.211176  \n",
      "30   -2.122652  2.552737 -1.669084 -0.218817 -0.058658  0.369721 -1.874821  \n",
      "45    0.002167 -0.906308  1.589740 -2.801030 -0.395230 -0.545860  0.449280  \n",
      "60    0.772210  0.638343  0.508935 -0.299673 -0.956307 -1.035473  1.281915  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "9930  0.208842  0.518936 -0.074853 -0.878505 -2.619039  0.581025  2.311122  \n",
      "9945 -0.191741 -0.464639  0.986370  0.543708  1.314496 -0.504171 -0.356893  \n",
      "9960 -0.940247  0.740099  0.418751 -0.194753 -0.569970 -0.514228 -0.401797  \n",
      "9975  0.320374 -0.584969  0.233773  0.619009  0.308602  0.062581 -0.317727  \n",
      "9990 -0.165783  1.312500  0.589015 -0.117900 -0.382385  1.418337  1.800148  \n",
      "\n",
      "[667 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_into_unique_samples(samples):#split into list of uique i.e 4,4,1,7,8,8.1 etc\n",
    "    samples_list = []\n",
    "    for i in samples['sample'].unique():   \n",
    "\n",
    "        samples_list.append(samples[samples['sample']==i].copy())\n",
    "    return samples_list\n",
    "def df_append(arr):\n",
    "    df = pd.DataFrame(columns = arr[0].columns)#generate data\n",
    "    for df_ in arr:\n",
    "        df = pd.concat([df,df_.copy()], ignore_index=True,axis=0,)\n",
    "    return df\n",
    "def split_X_y(df):\n",
    "    y = df['class'].copy()\n",
    "    X = df.drop('class',axis = 1).copy()\n",
    "    return X,y\n",
    "add = '/home/yishai/Dropbox/CyTOF_Breast/Kaplan_5th/_clusters.csv'\n",
    "dict = class_dict(add)\n",
    "drop_features = ['sample','cluster']\n",
    "feature_loc = 0\n",
    "samples = split_into_unique_samples(samples_.copy())#split into list of uique i.e 4,4,1,7,8,8.1 etc -\n",
    "for samp in samples: # iterate on uniq sample\n",
    "    ind0 = samp.index[0]\n",
    "    sampleID = samp.loc[ind0]['sample']\n",
    "    # try:\n",
    "    samp.insert(feature_loc,'class',[int(dict[(sampleID, cluster)]) for  cluster in samp['cluster'].copy()])\n",
    "    samp.drop(drop_features,axis = 1,inplace = True)\n",
    "    # except:pass\n",
    "print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6667, 20) (6667,) (3333, 20) (3333,)\n",
      "columns: Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# split data to train and test, merge samples to single df and split  to X and y\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "train, test  = tts(samples,test_size = 0.3,random_state = 42,shuffle = True)#list of df's by samples\n",
    "\n",
    "X_test,y_test = split_X_y(df_append(test.copy()))\n",
    "X_train,y_train = split_X_y(df_append(train.copy()))\n",
    "print(X_train.shape,y_train.shape, X_test.shape,y_test.shape)\n",
    "print(f'columns: {X_train.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to pytorch tensor and build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class ColumnarDataset(Dataset):#return random columns from df in a torch tensor\n",
    "    def __init__(self, df,y, cats=[]):\n",
    "        \n",
    "        # # categorial data - according to categorial feature list (cats)\n",
    "        # self.dfcats = df[cats] #type: pandas.core.frame.DataFrame\n",
    "        # self.cats = np.stack([c.values for n, c in self.dfcats.items()], axis=1).astype(np.int64) #tpye: numpy.ndarray\n",
    "        # continus data\n",
    "        self.dfconts = df.drop(cats, axis=1) #type: pandas.core.frame.DataFram\n",
    "        self.X = np.stack([c.values for n, c in self.dfconts.items()], axis=1).astype(np.float32) #tpye: numpy.ndarray\n",
    "        # y\n",
    "        self.y = y.values.astype(np.float32)\n",
    "        \n",
    "        \n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "        return [ self.X[idx], self.y[idx]]\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': True,\n",
    "            'num_workers': 6,\n",
    "            'drop_last' :True,\n",
    "\n",
    "\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(ColumnarDataset(X_train.copy(),  y_train.copy()), **params) #type: torch.utils.data.dataloader.DataLoader\n",
    "test_dataloader = DataLoader(ColumnarDataset(X_test.copy(),  y_test.copy()), **params) #type: torch.utils.data.dataloader.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 2., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 2., 1., 0., 0., 1.,\n",
       "        0., 3., 1., 1., 0., 2., 0., 3., 2., 1., 1., 0., 1., 2., 2., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 3., 1., 1., 3., 0., 1., 0., 2., 1., 2., 1.,\n",
       "        1., 0., 0., 1., 3., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        2., 2., 2., 1., 2., 2., 3., 0., 0., 2., 1., 0., 0., 2., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 2., 1., 1., 1., 2., 1., 2., 1., 2., 2., 2., 1.,\n",
       "        1., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = next(iter(train_dataloader))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch tabular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch_tabular list of models: ['CategoryEmbeddingModelConfig', 'NodeConfig', 'TabNetModelConfig', 'MDNConfig', 'AutoIntConfig', 'TabTransformerConfig', 'FTTransformerConfig', 'GatedAdditiveTreeEnsembleConfig']\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.ssl_models.dae import DenoisingAutoEncoderConfig\n",
    "from pytorch_tabular import  models\n",
    "\n",
    "print (f\"pytorch_tabular list of models: {[f for f in models.__all__ if 'Config'  in f ]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GatedAdditiveTreeEnsembleModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_tabular\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GatedAdditiveTreeEnsembleConfig\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mGatedAdditiveTreeEnsembleModel\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GatedAdditiveTreeEnsembleModel' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_tabular.models import GatedAdditiveTreeEnsembleConfig\n",
    "print(GatedAdditiveTreeEnsembleModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <th>Soil_Type1</th>\n",
       "      <th>Soil_Type2</th>\n",
       "      <th>Soil_Type3</th>\n",
       "      <th>Soil_Type4</th>\n",
       "      <th>Soil_Type5</th>\n",
       "      <th>Soil_Type6</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wilderness_Area1  Wilderness_Area2  Wilderness_Area3  Wilderness_Area4  \\\n",
       "0                 1                 0                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 1                 0                 0                 0   \n",
       "\n",
       "   Soil_Type1  Soil_Type2  Soil_Type3  Soil_Type4  Soil_Type5  Soil_Type6  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   ...  Soil_Type31  Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  \\\n",
       "0  ...            0            0            0            0            0   \n",
       "1  ...            0            0            0            0            0   \n",
       "2  ...            0            0            0            0            0   \n",
       "3  ...            0            0            0            0            0   \n",
       "4  ...            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0            0            0  \n",
       "1            0            0            0            0            0  \n",
       "2            0            0            0            0            0  \n",
       "3            0            0            0            0            0  \n",
       "4            0            0            0            0            0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_name = \"Covertype\"\n",
    "\n",
    "cat_col_names = [\n",
    "    \"Wilderness_Area1\",\n",
    "    \"Wilderness_Area2\",\n",
    "    \"Wilderness_Area3\",\n",
    "    \"Wilderness_Area4\",\n",
    "    \"Soil_Type1\",\n",
    "    \"Soil_Type2\",\n",
    "    \"Soil_Type3\",\n",
    "    \"Soil_Type4\",\n",
    "    \"Soil_Type5\",\n",
    "    \"Soil_Type6\",\n",
    "    \"Soil_Type7\",\n",
    "    \"Soil_Type8\",\n",
    "    \"Soil_Type9\",\n",
    "    \"Soil_Type10\",\n",
    "    \"Soil_Type11\",\n",
    "    \"Soil_Type12\",\n",
    "    \"Soil_Type13\",\n",
    "    \"Soil_Type14\",\n",
    "    \"Soil_Type15\",\n",
    "    \"Soil_Type16\",\n",
    "    \"Soil_Type17\",\n",
    "    \"Soil_Type18\",\n",
    "    \"Soil_Type19\",\n",
    "    \"Soil_Type20\",\n",
    "    \"Soil_Type21\",\n",
    "    \"Soil_Type22\",\n",
    "    \"Soil_Type23\",\n",
    "    \"Soil_Type24\",\n",
    "    \"Soil_Type25\",\n",
    "    \"Soil_Type26\",\n",
    "    \"Soil_Type27\",\n",
    "    \"Soil_Type28\",\n",
    "    \"Soil_Type29\",\n",
    "    \"Soil_Type30\",\n",
    "    \"Soil_Type31\",\n",
    "    \"Soil_Type32\",\n",
    "    \"Soil_Type33\",\n",
    "    \"Soil_Type34\",\n",
    "    \"Soil_Type35\",\n",
    "    \"Soil_Type36\",\n",
    "    \"Soil_Type37\",\n",
    "    \"Soil_Type38\",\n",
    "    \"Soil_Type39\",\n",
    "    \"Soil_Type40\",\n",
    "]\n",
    "\n",
    "num_col_names = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "]\n",
    "\n",
    "feature_columns = num_col_names + cat_col_names + [target_name]\n",
    "datafile = '/home/yishai/Downloads/covtype.data.gz'\n",
    "\n",
    "data = pd.read_csv(datafile, header=None, names=feature_columns)\n",
    "#Dropping NA rows\n",
    "data.dropna(inplace=True)\n",
    "# drop categorial features\n",
    "# data.drop(cat_col_names, axis=1, inplace=True)\n",
    "# cat_col_names = []\n",
    "data[cat_col_names].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Wilderness_Area1'\t].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Covertype'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 19:11:54,217 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n"
     ]
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[target_name],\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    "    normalize_continuous_features=True,#change to false - our case they are normalized\n",
    ")\n",
    "trainer_params = {\n",
    "                'batch_size': 2048,\n",
    "                'max_epochs' : 10,\n",
    "                'early_stopping': None,\n",
    "                'checkpoints': 'valid_loss', # Save best checkpoint monitoring val_loss\n",
    "                'load_best': True,# After training, load the best checkpoint\n",
    "                'accelerator': 'auto',# can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    "                'devices': -1,# -1 means use all available\n",
    "                'auto_lr_find': True, # Runs the LRFinder to automatically derive a learning rate\n",
    "\n",
    "            # 'early_stopping_patience': 5,\n",
    "            # 'early_stopping_mode': 'min',\n",
    "                        \n",
    "}\n",
    "\n",
    "#default values\n",
    "optimizer_params = {'optimizer': 'Adam', 'optimizer_params':{},\n",
    "                    'lr_scheduler': None, 'lr_scheduler_params':{},\n",
    "                    'lr_scheduler_monitor_metric': \"valid_loss\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"2000-1000\",\n",
    "    activation=\"ReLU\",\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    "    head=\"LinearHead\",\n",
    "    head_config={\n",
    "        \"layers\": \"\",\n",
    "        \"activation\": \"ReLU\",\n",
    "    },\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=OptimizerConfig(**optimizer_params),\n",
    "    trainer_config=TrainerConfig(**trainer_params),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabelled Data: 575201 rows | Labelled Data: 5811\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into data for SSL and data for finetuning\n",
    "ssl, finetune = tts(data, random_state=42, test_size=0.01)\n",
    "# Train and val splits\n",
    "ssl_train, ssl_val = tts(ssl, random_state=42)\n",
    "df_finetune_train, df_finetune_test = tts(finetune, random_state=42)\n",
    "df_finetune_train, df_finetune_val = tts(df_finetune_train, random_state=42)\n",
    "print(f\"Unlabelled Data: {ssl.shape[0]} rows | Labelled Data: {finetune.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "2023-11-29 19:03:30,425 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-11-29 19:03:30,428 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "2023-11-29 19:03:30,731 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-11-29 19:03:30,999 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "/home/yishai/anaconda3/envs/torch39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-11-29 19:03:31,060 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  2.2 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │    276 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │  7.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss          │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  2.2 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │    276 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │  7.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss          │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.2 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.2 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 8                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.2 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.2 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 8                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c687b0baf0543fd8e8e9d4b5f25e848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 19:03:42,192 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-11-29 19:03:42,193 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/yishai/anaconda3/envs/torch39/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x7f38fa25e5e0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.fit(\n",
    "    train=df_finetune_train, \n",
    "    validation=df_finetune_val\n",
    ")\n",
    "# pytorch_tabular.TabularModel.fit(train, validation=None, test=None, loss=None, metrics=None, metrics_prob_inputs=None, \n",
    "#                                  optimizer=None, optimizer_params={}, train_sampler=None, target_transform=None, max_epochs=None, \n",
    "#                                  min_epochs=None, seed=42, callbacks=None, datamodule=None, cache_data='memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4530e-01, -4.1552e-01, -1.9532e-01,  ..., -8.7123e-01,\n",
       "         -1.7257e-01, -4.9891e-01],\n",
       "        [ 7.7081e-01,  4.4592e-02, -1.6168e-01,  ...,  3.5759e-01,\n",
       "          1.3452e-01, -7.4229e-01],\n",
       "        [-6.9226e-01, -4.1679e-01,  7.8445e-02,  ...,  1.4433e-03,\n",
       "          1.1191e+00,  7.8265e-01],\n",
       "        ...,\n",
       "        [ 1.0534e+00,  3.0848e-01, -9.8421e-01,  ...,  4.5615e-01,\n",
       "          1.3803e+00, -1.8561e-01],\n",
       "        [-7.3249e-01, -1.2989e+00,  3.8116e-01,  ..., -9.1017e-01,\n",
       "          1.2457e+00, -4.2385e-01],\n",
       "        [ 1.1645e+00, -1.6287e+00, -2.0924e-01,  ...,  3.9179e-02,\n",
       "          5.1680e-03,  5.7231e-01]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as torch_optim\n",
    "from torchvision import models\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.optim import lr_scheduler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
