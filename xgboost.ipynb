{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Create some example data\n",
    "X = np.random.rand(100, 5)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "# Convert the data to a DMatrix, which is the input format for XGBoost\n",
    "dmat = xgb.DMatrix(X, label=y)\n",
    "\n",
    "# Set the parameters for the model\n",
    "params = {\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.5,\n",
    "    'eta': 0.1\n",
    "}\n",
    "\n",
    "# Fit the model\n",
    "bst = xgb.train(params, dmat, num_boost_round=100)\n",
    "\n",
    "# This example uses random data for the inputs and outputs, but in practice you would use your own data. The params dictionary contains the parameters for the model, such as the objective function to optimize, the evaluation metric to use, and the maximum depth of the decision trees. The num_boost_round parameter controls the number of boosting rounds to perform.\n",
    "\n",
    "# You can use the bst object to make predictions on new data or to extract information about the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8f0ead6d24b021015c699f739debaba8c1078b555894facc5ccdb37f4bd0e50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
